{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import tf_glove\n",
    "import pickle\n",
    "%matplotlib  inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn embedings with Glove algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('Tra.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def convert_to_lem(text):\n",
    "    tokens = []\n",
    "    for word in  nltk.word_tokenize(text, language='english'):\n",
    "        #if len(word) < 2:\n",
    "            #continue\n",
    "        tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "    return tokens\n",
    "\n",
    "def tokenize_on_whitespace(sent):\n",
    "    result = []\n",
    "    for w in WhitespaceTokenizer().tokenize(sent):\n",
    "        result.append(w.lower())\n",
    "    return result\n",
    "def word_sort_by_freq(series, threshold):\n",
    "    threshold += 1\n",
    "    df_array = series.values.tolist()\n",
    "    flattend = []\n",
    "    for row in df_array:\n",
    "        flattend += row\n",
    "    dist = FreqDist(flattend)\n",
    "    sortedToken = sorted(list(set(flattend)), key=lambda token: dist[token], reverse=False)\n",
    "    word_freq_sorted = [(token, dist[token]) for token in sortedToken]\n",
    "\n",
    "    for idx in range(len(word_freq_sorted)):\n",
    "        if word_freq_sorted[idx][1] == threshold:\n",
    "            start = idx\n",
    "            break\n",
    "    return  word_freq_sorted[start:]\n",
    "    \n",
    "def word_with_freq_above_treshold(series, threshold=4):\n",
    "    word_freq_sorted = word_sort_by_freq(series, threshold)\n",
    "    result = [line[0] for line in word_freq_sorted]    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150164    52\n",
      "387521    52\n",
      "79671     46\n",
      "151256    45\n",
      "479672    44\n",
      "214038    43\n",
      "184062    42\n",
      "8766      41\n",
      "283195    40\n",
      "5906      40\n",
      "Name: Text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tokens = train_df['Text'].apply(convert_to_lem)\n",
    "tokens = tokens.apply(lambda x: len(x))\n",
    "tokens.plot.hist()\n",
    "print(tokens.sort_values(ascending=False).head(10))\n",
    "max_num_words = (tokens.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = [\"abcde\", \"abcde\", \"abcde\", \"abcde\", \"abcde\"]\n",
    "def add_pad(tkn):\n",
    "    return tkn + pad\n",
    "def Glove_TF(text, lemas=True):\n",
    "    \"\"\"Train word 2 vec\"\"\"\n",
    "    if lemas:\n",
    "        corp = text.apply(convert_to_lem)\n",
    "    else:\n",
    "        corp = text.apply(tokenize_on_whitespace)\n",
    "    corp = corp.apply(add_pad)\n",
    "    \n",
    "    model  =  tf_glove.GloVeModel(embedding_size=50, context_size=5, min_occurrences=5,\n",
    "                                learning_rate=0.05, batch_size=256)    \n",
    "    model.fit_to_corpus(corp)\n",
    "    model.train(num_epochs=1, summary_batch_interval=512)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_m = Glove_TF(train_df['Text'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lema_m = Glove_TF(train_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_idx(text, model, lemas=True):\n",
    "    if lemas:\n",
    "        corp = text.apply(convert_to_lem)\n",
    "    else:\n",
    "        corp = text.apply(tokenize_on_whitespace)\n",
    "    corp = corp.apply(add_pad)\n",
    "\n",
    "    word_above_tresh = word_with_freq_above_treshold(corp, 4)\n",
    "    i = 0\n",
    "    \n",
    "    my_words_to_index = {}\n",
    "    my_index_to_words = {}\n",
    "    my_word_to_vec_map = {}\n",
    "    for w in sorted(word_above_tresh):\n",
    "        i = i + 1\n",
    "        my_words_to_index[w] = i\n",
    "        my_index_to_words[i] = w\n",
    "        my_word_to_vec_map[w] = model.embedding_for(w)\n",
    "    return my_words_to_index, my_index_to_words, my_word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_words_to_index_low, my_index_to_words_low, my_word_to_vec_map_low = conv_to_idx(train_df['Text'],norm_m, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(my_word_to_vec_map_low, open( \"w2v_low_map.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_words_to_index_lem, my_index_to_words_lem, my_word_to_vec_map_lem = conv_to_idx(train_df['Text'],lema_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(my_words_to_index_lem, open( \"w2v_low_map.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
